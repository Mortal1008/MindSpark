import os
import time
from math import ceil
import pandas as pd
import streamlit as st
import os


def get_unique_files_info(ref_doc_info):
    docs = []
    seen_paths = set()

    for ref_doc_id, ref_doc in ref_doc_info.items():

        metadata = ref_doc.metadata
        file_path = metadata.get("file_path", None)

        if file_path is None:
            title = metadata.get("title", None)
            url = metadata.get("url_source", None)
            docs.append(
                {
                    "id": ref_doc_id,
                    "name": title,
                    "type": "url",
                    "path": url,
                    "date": metadata["creation_date"],
                    "tags": metadata.get("tags", []),
                }
            )

        if file_path and file_path not in seen_paths:
            base_name, extension = os.path.splitext(metadata["file_name"])
            # Remove the leading dot from the extension
            extension = extension.lstrip(".")

            file_info = {
                "id": ref_doc_id,
                "name": base_name,
                "type": extension,
                "path": file_path,
                #'file_size': metadata['file_size'],
                "date": metadata["creation_date"],
                "tags": metadata.get("tags", []),
            }
            docs.append(file_info)
            seen_paths.add(file_path)

    return docs


def handle_knowledgebase():
    st.header("Manage Knowledge Base")
    st.caption("Manage documents and web urls in your knowledge base.")

    from server.stores.strage_context import STORAGE_CONTEXT

    doc_store = STORAGE_CONTEXT.docstore

    try:
        # ç›´æ¥å°è¯•è·å–æ‰€æœ‰å¼•ç”¨æ–‡æ¡£ä¿¡æ¯ï¼Œä¸ä¾èµ–doc_store.docså±æ€§
        # è¿™å¯¹RedisDocumentStoreç­‰ç”Ÿäº§ç¯å¢ƒä¸­çš„å­˜å‚¨æ›´å…¼å®¹
        ref_doc_info = doc_store.get_all_ref_doc_info()

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
        if not ref_doc_info:
            st.write("Knowledge base is empty")
            return  # æå‰è¿”å›ï¼Œé¿å…åç»­å¤„ç†

        # å¤„ç†æ–‡æ¡£åˆ—è¡¨
        unique_files = get_unique_files_info(ref_doc_info)
        st.write("You have total", len(unique_files), "documents.")
        df = pd.DataFrame(unique_files)
    except Exception as e:
        print(f"Error getting document info: {e}")
        st.error("Failed to load document information. Please try again.")
        st.write("Knowledge base is empty")
        return  # æå‰è¿”å›ï¼Œé¿å…åç»­å¤„ç†

    # è·å–æ‰€æœ‰å”¯ä¸€æ ‡ç­¾ç”¨äºæœç´¢
    all_tags = set()
    for _, row in df.iterrows():
        tags = row["tags"]
        if isinstance(tags, list):
            all_tags.update(tags)
        elif isinstance(tags, str) and tags:
            all_tags.update([tag.strip() for tag in tags.split(",") if tag.strip()])

    # æ·»åŠ é«˜çº§æœç´¢åŠŸèƒ½
    st.subheader("Search")

    # åˆ›å»ºæœç´¢æ¡ä»¶åŒºåŸŸ
    with st.expander("Search Criteria", expanded=True):
        # åˆå§‹åŒ–æœç´¢æ¡ä»¶ä¼šè¯çŠ¶æ€
        if "search_conditions" not in st.session_state:
            st.session_state.search_conditions = [
                {"logic": "AND", "field": "tags", "value": "", "id": 0}
            ]
            st.session_state.next_condition_id = 1

        # è·å–æ‰€æœ‰å”¯ä¸€çš„æ–‡æ¡£ç±»å‹
        all_types = set(df["type"].unique())

        # å®šä¹‰å¯æœç´¢å­—æ®µ
        search_fields = {"tags": "æ ‡ç­¾", "type": "æ–‡æ¡£ç±»å‹", "name": "æ–‡æ¡£åç§°"}

        # æ˜¾ç¤ºæœç´¢æ¡ä»¶
        # æ˜¾ç¤ºæœç´¢æ¡ä»¶
        for i, condition in enumerate(st.session_state.search_conditions):
            # ç»Ÿä¸€ä½¿ç”¨ç›¸åŒçš„åˆ—å¸ƒå±€ï¼Œç¡®ä¿æ‰€æœ‰è¡Œå¯¹é½
            cols = st.columns([1, 2, 4, 1])

            # é€»è¾‘è¿ç®—ç¬¦é€‰æ‹©å™¨ - ä»…åœ¨éç¬¬ä¸€è¡Œæ˜¾ç¤º
            if i != 0:
                condition["logic"] = cols[0].selectbox(
                    "Logic",
                    options=["AND", "OR", "NOT"],
                    index=["AND", "OR", "NOT"].index(condition["logic"]),
                    key=f"logic_{condition['id']}",
                    help="é€‰æ‹©é€»è¾‘è¿ç®—ç¬¦",
                )

            # å­—æ®µé€‰æ‹©å™¨
            condition["field"] = cols[1].selectbox(
                "Field",
                options=list(search_fields.keys()),
                format_func=lambda x: search_fields[x],
                key=f"field_{condition['id']}",
                help="é€‰æ‹©è¦æœç´¢çš„å­—æ®µ",
            )

            # å€¼è¾“å…¥æ¡†
            if condition["field"] == "type":
                condition["value"] = cols[2].selectbox(
                    "Document Type",
                    options=[""] + sorted(all_types),
                    index=(
                        0
                        if condition["value"] == ""
                        else (
                            sorted(all_types).index(condition["value"]) + 1
                            if condition["value"] in all_types
                            else 0
                        )
                    ),
                    key=f"value_{condition['id']}",
                    help="é€‰æ‹©æ–‡æ¡£ç±»å‹",
                )
            elif condition["field"] == "tags":
                condition["value"] = cols[2].selectbox(
                    "Tags",
                    options=[""] + sorted(all_tags),
                    index=(
                        0
                        if condition["value"] == ""
                        else (
                            sorted(all_tags).index(condition["value"]) + 1
                            if condition["value"] in all_tags
                            else 0
                        )
                    ),
                    key=f"value_{condition['id']}",
                    help="é€‰æ‹©æ ‡ç­¾",
                )
            else:
                condition["value"] = cols[2].text_input(
                    "Search Text",
                    value=condition["value"],
                    key=f"value_{condition['id']}",
                    label_visibility="collapsed",
                )

            # åˆ é™¤æŒ‰é’® - ä»…åœ¨éç¬¬ä¸€è¡Œæ˜¾ç¤ºåƒåœ¾æ¡¶å›¾æ ‡ï¼Œå¹¶å‚ç›´å±…ä¸­
            if i != 0:
                with cols[3]:
                    # æ·»åŠ åˆ é™¤æ–‡æœ¬æ ‡ç­¾
                    st.markdown(
                        "<div style='font-size: 14px; margin-bottom: 5px;'>DEL</div>",
                        unsafe_allow_html=True,
                    )

                    # æ·»åŠ åˆ é™¤æŒ‰é’®
                    if st.button("ğŸ—‘ï¸", key=f"remove_{condition['id']}", help="åˆ é™¤æ¡ä»¶"):
                        st.session_state.search_conditions = [
                            c
                            for c in st.session_state.search_conditions
                            if c["id"] != condition["id"]
                        ]
                        st.rerun()

        # æ·»åŠ æ–°æ¡ä»¶æŒ‰é’®
        if st.button("+ Add Search Condition"):
            st.session_state.search_conditions.append(
                {
                    "logic": "AND",
                    "field": "tags",
                    "value": "",
                    "id": st.session_state.next_condition_id,
                }
            )
            st.session_state.next_condition_id += 1
            st.rerun()

    # æ ¹æ®æœç´¢æ¡ä»¶è¿‡æ»¤æ–‡æ¡£
    filtered_docs = []
    has_active_conditions = False

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æœç´¢æ¡ä»¶
    for condition in st.session_state.search_conditions:
        if condition["value"] != "":
            has_active_conditions = True
            break

    if has_active_conditions:
        # éå†æ‰€æœ‰æ–‡æ¡£
        for _, row in df.iterrows():
            # æ–‡æ¡£æ˜¯å¦åŒ¹é…æ‰€æœ‰æ¡ä»¶
            doc_matches = True

            # è·Ÿè¸ªæ˜¯å¦å·²ç»å¤„ç†äº†è‡³å°‘ä¸€ä¸ªéç©ºæ¡ä»¶
            has_processed_condition = False

            # éå†æ‰€æœ‰æœç´¢æ¡ä»¶
            for i, condition in enumerate(st.session_state.search_conditions):
                # è·³è¿‡ç©ºå€¼æ¡ä»¶
                if condition["value"] == "":
                    continue

                # æ ¹æ®å­—æ®µç±»å‹æ£€æŸ¥æ¡ä»¶æ˜¯å¦åŒ¹é…
                match = False

                if condition["field"] == "type":
                    match = row["type"] == condition["value"]
                elif condition["field"] == "tags":
                    doc_tags = row["tags"]
                    if isinstance(doc_tags, list):
                        tags_list = doc_tags
                    elif isinstance(doc_tags, str):
                        tags_list = [
                            tag.strip() for tag in doc_tags.split(",") if tag.strip()
                        ]
                    else:
                        tags_list = []
                    match = condition["value"] in tags_list
                elif condition["field"] == "name":
                    match = condition["value"].lower() in str(row["name"]).lower()

                # åº”ç”¨é€»è¾‘è¿ç®—ç¬¦
                if not has_processed_condition:
                    # ç¬¬ä¸€ä¸ªéç©ºæ¡ä»¶ç›´æ¥è®¾ç½®ç»“æœ
                    doc_matches = match
                    has_processed_condition = True
                else:
                    # åç»­æ¡ä»¶åº”ç”¨é€»è¾‘è¿ç®—ç¬¦
                    # å¯¹äºéç¬¬ä¸€è¡Œçš„æ¡ä»¶ï¼Œä½¿ç”¨å…¶æŒ‡å®šçš„é€»è¾‘è¿ç®—ç¬¦
                    if condition["logic"] == "AND":
                        doc_matches = doc_matches and match
                    elif condition["logic"] == "OR":
                        doc_matches = doc_matches or match
                    elif condition["logic"] == "NOT":
                        doc_matches = doc_matches and not match

            # å¦‚æœæ–‡æ¡£åŒ¹é…æ‰€æœ‰æ¡ä»¶ï¼Œæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            if doc_matches:
                filtered_docs.append(row)

        df = pd.DataFrame(filtered_docs)
        st.write(f"Found {len(df)} documents matching search criteria.")

    # ç¡®ä¿tagsåˆ—å­˜åœ¨å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ä»¥ä¾¿æ˜¾ç¤º
    if "tags" not in df.columns:
        df["tags"] = ""
    else:
        df["tags"] = df["tags"].apply(
            lambda x: (
                ", ".join(x) if isinstance(x, list) and x else (str(x) if x else "")
            )
        )

    # Pagination settings

    page_size = 12
    total_pages = ceil(len(df) / page_size)

    if "curr_page" not in st.session_state.keys():
        st.session_state.curr_page = 1

    curr_page = min(st.session_state["curr_page"], total_pages)

    # Displaying pagination buttons
    if total_pages > 1:
        prev, next, _, col3 = st.columns([1, 1, 6, 2])

        if next.button("Next"):
            curr_page = min(curr_page + 1, total_pages)
            st.session_state["curr_page"] = curr_page

        if prev.button("Prev"):
            curr_page = max(curr_page - 1, 1)
            st.session_state["curr_page"] = curr_page

        with col3:
            st.write("Page: ", curr_page, "/", total_pages)

    start_index = (curr_page - 1) * page_size
    end_index = curr_page * page_size
    df_paginated = df.iloc[start_index:end_index]

    # åˆ›å»ºä¸€ä¸ªDataFrameå‰¯æœ¬ï¼Œç”¨äºæ˜¾ç¤º
    df_display = df_paginated.copy()

    # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œå¸®åŠ©ç¡®è®¤DataFrameç¡®å®åŒ…å«æ•°æ®
    if not df_display.empty:
        st.write(f"æ˜¾ç¤ºç¬¬ {curr_page} é¡µï¼Œå…± {len(df_display)} ä¸ªæ–‡æ¡£")
    else:
        st.info("å½“å‰é¡µæ²¡æœ‰æ–‡æ¡£")

    # ä½¿ç”¨data_editorå®ç°åŒå‡»ç¼–è¾‘æ ‡ç­¾åŠŸèƒ½
    if not df_display.empty:
        # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
        display_columns = ["name", "type", "date", "tags"]
        display_df = df_display[display_columns].copy()

        # ç¡®ä¿æ ‡ç­¾åˆ—æ˜¾ç¤ºä¸ºå­—ç¬¦ä¸²
        display_df["tags"] = display_df["tags"].apply(
            lambda x: (
                ", ".join(x) if isinstance(x, list) and x else (str(x) if x else "")
            )
        )

        # å­˜å‚¨åŸå§‹æ–‡æ¡£IDä¸æ˜¾ç¤ºè¡Œçš„æ˜ å°„
        doc_id_map = {idx: doc["id"] for idx, doc in df_display.iterrows()}

        # åˆ›å»ºå¯ç¼–è¾‘çš„æ•°æ®è¡¨æ ¼
        edited_df = st.data_editor(
            display_df,
            width=800,
            column_config={
                "name": st.column_config.TextColumn("Name", width=300, disabled=True),
                "type": st.column_config.TextColumn("Type", width=100, disabled=True),
                "date": st.column_config.TextColumn(
                    "Creation Date", width=150, disabled=True
                ),
                "tags": st.column_config.TextColumn("Tags", width=250),
            },
            hide_index=True,
            use_container_width=True,
            key="doc_editor",
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼–è¾‘å¹¶æ›´æ–°æ ‡ç­¾
        if st.session_state.get("doc_editor", None) is not None:
            # è·å–ç¼–è¾‘çš„å•å…ƒæ ¼ä¿¡æ¯
            edited_cells = st.session_state.doc_editor.get("edited_cells", {})
            if edited_cells:
                # è·å–æ–‡æ¡£IDåˆ°åŸå§‹ç´¢å¼•çš„æ˜ å°„
                id_to_original_idx = {
                    doc["id"]: idx for idx, doc in df_display.iterrows()
                }

                # éå†æ‰€æœ‰ç¼–è¾‘çš„å•å…ƒæ ¼
                for row_idx, col_dict in edited_cells.items():
                    if "tags" in col_dict:
                        # è·å–åŸå§‹æ–‡æ¡£ç´¢å¼•
                        original_idx = int(row_idx)
                        doc_id = doc_id_map[original_idx]

                        # è·å–æ›´æ–°åçš„æ ‡ç­¾
                        new_tags = edited_df.iloc[original_idx]["tags"]

                        # å¤„ç†æ ‡ç­¾æ ¼å¼
                        tags_list = [
                            tag.strip() for tag in new_tags.split(",") if tag.strip()
                        ]
                        tags_str = ", ".join(tags_list)

                        try:
                            # è·å–åŸå§‹æ–‡æ¡£å¼•ç”¨ä¿¡æ¯
                            ref_doc = ref_doc_info[doc_id]

                            # æ›´æ–°æ–‡æ¡£å…ƒæ•°æ®ä¸­çš„æ ‡ç­¾
                            if hasattr(ref_doc, "metadata") and isinstance(
                                ref_doc.metadata, dict
                            ):
                                ref_doc.metadata["tags"] = tags_str

                                # æ›´æ–°æ–‡æ¡£å­˜å‚¨
                                doc_store.set_ref_doc_info({doc_id: ref_doc})

                                # æŒä¹…åŒ–å­˜å‚¨ä¸Šä¸‹æ–‡
                                STORAGE_CONTEXT.persist()

                                st.toast(f"âœ”ï¸ æ ‡ç­¾å·²æ›´æ–°: {tags_str}", icon="ğŸ‰")
                        except Exception as e:
                            print(f"Error updating tags for document {doc_id}: {e}")
                            st.error(f"æ›´æ–°æ ‡ç­¾å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")

        # ä¿ç•™åˆ é™¤åŠŸèƒ½æ‰€éœ€çš„doc_optionsåˆ›å»º
        doc_options = {
            f"{doc['name']} ({doc['type']})": doc["id"]
            for _, doc in df_display.iterrows()
        }
    else:
        doc_options = {}

    # æ˜¾ç¤ºåˆ é™¤æŒ‰é’®åŒºåŸŸ

    # æ·»åŠ ä¼šè¯çŠ¶æ€å˜é‡æ¥å­˜å‚¨å½“å‰é€‰ä¸­çš„æ–‡æ¡£ID
    if "selected_doc_id" not in st.session_state:
        st.session_state.selected_doc_id = None

    # æ˜¾ç¤ºåˆ é™¤æŒ‰é’®åŒºåŸŸ
    st.markdown("### Delete Document")

    # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„doc_optionså˜é‡ï¼Œä¸éœ€è¦é‡æ–°åˆ›å»º

    if doc_options:
        selected_doc_name = st.selectbox(
            "Select a document to delete:",
            options=list(doc_options.keys()),
            help="Select a document to delete",
        )

        if selected_doc_name:
            selected_doc_id = doc_options[selected_doc_name]

            # åˆ é™¤ç¡®è®¤å¯¹è¯æ¡†
            if st.button(
                "ğŸ—‘ï¸ Delete Selected Document", type="primary", key="delete_selected"
            ):
                with st.spinner(text="Deleting document and related index..."):
                    st.session_state.index_manager.delete_ref_doc(selected_doc_id)
                    st.toast(
                        f'âœ”ï¸ Deleted document: {selected_doc_name.split(" (")[0]}',
                        icon="ğŸ‰",
                    )
                    time.sleep(2)
                    st.rerun()
    else:
        st.info("No documents to delete on this page.")

    # æ ‡ç­¾ç¼–è¾‘åŠŸèƒ½å·²é€šè¿‡data_editorå®ç°
    # ä»¥ä¸‹æ˜¯æ—§çš„ç¼–è¾‘åŠŸèƒ½ä»£ç ï¼Œå·²è¢«å†…è”ç¼–è¾‘åŠŸèƒ½å–ä»£
    st.caption(
        "ğŸ’¡ You can double-click on any tag cell to edit it directly in the table above."
    )
    st.caption("ğŸ’¡ ä¸åŒæ ‡ç­¾ç”¨è‹±æ–‡é€—å·åˆ†éš”")


handle_knowledgebase()
