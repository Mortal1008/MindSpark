import time
import streamlit as st
import time
import pandas as pd

# å¯¼å…¥æ‰€éœ€çš„ç½‘é¡µè¯»å–å™¨
from server.readers.beautiful_soup_web import BeautifulSoupWebReader
from server.readers.jina_web import JinaWebReader


def handle_website():
    # ç¡®ä¿session_stateä¸­æœ‰å¿…è¦çš„é…ç½®å‚æ•°
    if "websites" not in st.session_state:
        st.session_state["websites"] = []

    # åˆå§‹åŒ–chunk_sizeå’Œchunk_overlapå‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼
    if "chunk_size" not in st.session_state:
        st.session_state.chunk_size = 1000  # é»˜è®¤å€¼ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´

    if "chunk_overlap" not in st.session_state:
        st.session_state.chunk_overlap = 200  # é»˜è®¤å€¼ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´

    # ç¡®ä¿session_stateä¸­æœ‰é¢„è§ˆç›¸å…³çš„é…ç½®
    if "preview_content" not in st.session_state:
        st.session_state.preview_content = None
    if "preview_title" not in st.session_state:
        st.session_state.preview_title = None
    if "show_preview" not in st.session_state:
        st.session_state.show_preview = False
    if "preview_error" not in st.session_state:
        st.session_state.preview_error = None

    st.header("Load Web Pages")
    st.caption(
        "Enter URLs and optionally give custom names for web pages to add to the knowledge base."
    )

    with st.form("website-form", clear_on_submit=True):
        st.markdown("### Add Website")
        col1, col2 = st.columns([0.7, 0.3])
        with col1:
            new_website = st.text_input(
                "Web page address", placeholder="https://example.com"
            )
        with col2:
            custom_name = st.text_input(
                "Custom name (optional)", placeholder="Give a name"
            )
        tags_input = st.text_input(
            "Tags (optional)", placeholder="tag1, tag2", help="ä¸åŒæ ‡ç­¾ç”¨è‹±æ–‡é€—å·åˆ†éš”"
        )

        add_button = st.form_submit_button("Add")
        if add_button and new_website != "":
            # ä½¿ç”¨å­—å…¸å­˜å‚¨URLã€è‡ªå®šä¹‰åç§°å’Œæ ‡ç­¾
            # è§£ææ ‡ç­¾è¾“å…¥ï¼Œå»é™¤ç©ºæ ¼å¹¶è¿‡æ»¤ç©ºæ ‡ç­¾
            tags = []
            if tags_input:
                tags = [tag.strip() for tag in tags_input.split(",") if tag.strip()]

            website_info = {
                "url": new_website,
                "name": custom_name if custom_name else None,
                "tags": tags,
            }
            st.session_state["websites"].append(website_info)

    with st.expander(
        "Text processing parameter configuration",
        expanded=True,
    ):
        cols = st.columns(2)
        chunk_size = cols[0].number_input(
            "Maximum length of a single text block: ",
            1,
            4096,
            st.session_state.chunk_size,
            key="web_chunk_size",
        )
        chunk_overlap = cols[1].number_input(
            "Adjacent text overlap length: ",
            0,
            st.session_state.chunk_size,
            st.session_state.chunk_overlap,
            key="web_chunk_overlap",
        )

        # Add web reader selection
        reader_type = st.selectbox(
            "Web Page Reader Type:",
            options=["BeautifulSoup Reader", "Jina AI Reader"],
            index=0,
            help="BeautifulSoup Reader is basic but works offline. Jina AI Reader provides better content extraction but requires internet access.",
        )

    # æ·»åŠ URLå†…å®¹é¢„è§ˆå‡½æ•°
    def preview_url_content(url, reader_type):
        try:
            st.session_state.preview_error = None
            if reader_type == "Jina AI Reader":
                # ä½¿ç”¨Jinaé˜…è¯»å™¨
                reader = JinaWebReader()
                documents = reader.load_data([url])
            else:
                # ä½¿ç”¨BeautifulSoupé˜…è¯»å™¨
                reader = BeautifulSoupWebReader()
                documents = reader.load_data([url])

            if documents and len(documents) > 0:
                doc = documents[0]
                # è·å–æ ‡é¢˜å’Œå†…å®¹
                title = doc.metadata.get("title", "Preview")
                content = doc.text

                # æ›´æ–°session_stateä»¥æ˜¾ç¤ºé¢„è§ˆ
                st.session_state.preview_title = title
                st.session_state.preview_content = content
            else:
                st.session_state.preview_error = "æ— æ³•ä»è¯¥URLæå–å†…å®¹ã€‚"
        except Exception as e:
            st.session_state.preview_error = f"é¢„è§ˆå¤±è´¥: {str(e)}"
        finally:
            # æ˜¾ç¤ºé¢„è§ˆæ¨¡æ€æ¡†
            st.session_state.show_preview = True

    if st.session_state["websites"] != []:
        st.markdown("### Added Websites")

        # æ˜¾ç¤ºå·²æ·»åŠ çš„ç½‘ç«™åˆ—è¡¨å¹¶æä¾›åˆ é™¤ã€ç¼–è¾‘æ ‡ç­¾å’Œé¢„è§ˆåŠŸèƒ½
        for idx, site_info in enumerate(st.session_state["websites"]):
            url = site_info["url"]
            name = site_info["name"] or url  # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰åç§°ï¼Œæ˜¾ç¤ºURL
            current_tags = site_info.get("tags", [])

            st.markdown("---")
            st.subheader(name)
            st.caption(url)

            # æ˜¾ç¤ºå’Œç¼–è¾‘æ ‡ç­¾
            tags_str = ", ".join(current_tags) if current_tags else ""
            new_tags_str = st.text_input(
                "Tags", value=tags_str, placeholder="tag1, tag2", key=f"tags_{idx}"
            )

            # å¦‚æœæ ‡ç­¾è¾“å…¥æœ‰å˜åŒ–ï¼Œæ›´æ–°æ ‡ç­¾
            if new_tags_str != tags_str:
                # è§£ææ–°æ ‡ç­¾ï¼Œå»é™¤ç©ºæ ¼å¹¶è¿‡æ»¤ç©ºæ ‡ç­¾
                new_tags = [
                    tag.strip() for tag in new_tags_str.split(",") if tag.strip()
                ]
                st.session_state["websites"][idx]["tags"] = new_tags

            # æ·»åŠ æ“ä½œæŒ‰é’®åˆ—
            col1, col2 = st.columns(2)
            with col1:
                # æ·»åŠ é¢„è§ˆæŒ‰é’®
                if st.button("ğŸ‘ï¸ Preview", key=f"preview_{idx}", help="é¢„è§ˆURLå†…å®¹"):
                    preview_url_content(url, reader_type)
            with col2:
                # æ·»åŠ åˆ é™¤æŒ‰é’®
                if st.button(
                    "ğŸ—‘ï¸ Delete", key=f"delete_{idx}", help="Delete this website"
                ):
                    # ç›´æ¥åœ¨å›è°ƒä¸­åˆ é™¤ç½‘ç«™
                    del st.session_state["websites"][idx]
                    st.rerun()
        st.write("")

    process_button = st.button(
        "Save", key="process_website", disabled=len(st.session_state["websites"]) == 0
    )
    if process_button:
        print("Generating index...")
        with st.spinner(
            text="Loading documents and building the index, may take a minute or two"
        ):
            # ä½¿ç”¨æ‰€é€‰çš„è¯»å–å™¨ç±»å‹ï¼Œå¹¶ä¼ é€’å¸¦è‡ªå®šä¹‰åç§°çš„ç½‘ç«™åˆ—è¡¨
            if reader_type == "Jina AI Reader":
                st.session_state.index_manager.load_websites(
                    st.session_state["websites"],
                    chunk_size,
                    chunk_overlap,
                    reader_type="jina",
                )
            else:
                st.session_state.index_manager.load_websites(
                    st.session_state["websites"],
                    chunk_size,
                    chunk_overlap,
                    reader_type="beautifulsoup",
                )
            st.toast("âœ”ï¸ Knowledge base index generation complete", icon="ğŸ‰")
            st.session_state.websites = []
            time.sleep(4)
        st.rerun()

    # æ˜¾ç¤ºURLå†…å®¹é¢„è§ˆç•Œé¢ï¼ˆä½¿ç”¨è‡ªå®šä¹‰æ–¹å¼æ›¿ä»£st.modalï¼‰
    if st.session_state.show_preview:
        # æ·»åŠ ä¸€ä¸ªç‰¹æ®Šçš„å®¹å™¨æ¥æ˜¾ç¤ºé¢„è§ˆå†…å®¹
        st.markdown("---")
        st.subheader("URL Content Preview")

        # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„å®¹å™¨æ¥æ˜¾ç¤ºé¢„è§ˆå†…å®¹
        with st.container():
            if st.session_state.preview_error:
                st.error(st.session_state.preview_error)
            else:
                if st.session_state.preview_title:
                    st.markdown(f"### {st.session_state.preview_title}")
                if st.session_state.preview_content:
                    # é™åˆ¶å†…å®¹æ˜¾ç¤ºé•¿åº¦ï¼Œé¿å…è¿‡é•¿çš„å†…å®¹
                    max_content_length = 5000
                    if len(st.session_state.preview_content) > max_content_length:
                        st.text_area(
                            "Extracted Content",
                            value=st.session_state.preview_content[:max_content_length],
                            height=500,
                            disabled=True,
                        )
                        st.info(f"å†…å®¹è¿‡é•¿ï¼Œä»…æ˜¾ç¤ºå‰{max_content_length}ä¸ªå­—ç¬¦...")
                    else:
                        st.text_area(
                            "Extracted Content",
                            value=st.session_state.preview_content,
                            height=500,
                            disabled=True,
                        )

                    # æ·»åŠ å†…å®¹è´¨é‡åˆ¤æ–­æç¤º
                    content_length = len(st.session_state.preview_content.strip())
                    if content_length < 100:
                        st.warning(
                            "âš ï¸ æå–çš„å†…å®¹è¾ƒå°‘ï¼Œå¯èƒ½æ˜¯æ— æ•ˆå†…å®¹æˆ–æ— æ³•æ­£ç¡®è§£æçš„ç½‘é¡µã€‚"
                        )
                    elif content_length > 10000:
                        st.info(
                            "â„¹ï¸ æå–çš„å†…å®¹è¾ƒå¤šï¼Œå¯èƒ½åŒ…å«ä¸å¿…è¦çš„ä¿¡æ¯ï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦éœ€è¦å…¨éƒ¨å…¥åº“ã€‚"
                        )
                else:
                    st.info("æ²¡æœ‰æå–åˆ°å†…å®¹ã€‚")

            # å…³é—­é¢„è§ˆæŒ‰é’®
            if st.button("Close Preview", key="close_preview_button"):
                st.session_state.show_preview = False
                st.session_state.preview_content = None
                st.session_state.preview_title = None
                st.session_state.preview_error = None
                st.rerun()

        st.markdown("---")


handle_website()
